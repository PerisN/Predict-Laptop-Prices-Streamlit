{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## **Productionisation (Model Deserialization)**"
      ],
      "metadata": {
        "id": "MEQ014mR0li3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "y-kSouiUiLB7"
      },
      "outputs": [],
      "source": [
        "# Import Libraries\n",
        "\n",
        "import numpy as np\n",
        "from pickle import load\n",
        "\n",
        "import warnings \n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading pretrained models from pickle file\n",
        "\n",
        "dicts = load(open('/content/dicts_cols.pkl', 'rb'))\n",
        "scaler = load(open('/content/scaler.pkl', 'rb'))\n",
        "xgb_reg = load(open('/content/xgb_model.pkl', 'rb'))\n",
        "gb_reg = load(open('/content/gbr_model.pkl', 'rb'))\n",
        "rf_reg = load(open('/content/rf_model.pkl', 'rb'))"
      ],
      "metadata": {
        "id": "PNfI7OzojV1o"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Read the Query Data\n",
        "print(\"Enter Laptop Details\")\n",
        "\n",
        "# RAM Type options\n",
        "ram_type_options = dicts['RAM_Type'].keys()\n",
        "ram_type = input(f'Enter the RAM Type ({\", \".join(ram_type_options)}): ')\n",
        "\n",
        "# Processor options\n",
        "processor_options = dicts['Processor'].keys()\n",
        "processor = input(f'Enter the Processor ({\", \".join(processor_options)}): ')\n",
        "\n",
        "# Storage options\n",
        "storage_options = dicts['Storage'].keys()\n",
        "storage = input(f'Enter the Storage ({\", \".join(storage_options)}): ')\n",
        "\n",
        "# OS options\n",
        "os_options = dicts['OS'].keys()\n",
        "os = input(f'Enter the Operating System ({\", \".join(os_options)}): ')\n",
        "\n",
        "# Brand options\n",
        "brand_options = dicts['Brand'].keys()\n",
        "brand = input(f'Enter the Brand ({\", \".join(brand_options)}): ')\n",
        "\n",
        "ram_size = float(input('Enter the RAM Size: '))\n",
        "display = float(input('Enter the Display Size: '))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CXzMeVZqyDVD",
        "outputId": "9d0e5886-8571-4583-86af-0a9917a41ff9"
      },
      "execution_count": 6,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter Laptop Details\n",
            "Enter the RAM Type (DDR4, DDR5, LPDDR3, LPDDR4, LPDDR4X, LPDDR5, Unified Memory): Unified Memory\n",
            "Enter the Processor (AMD Athlon Dual Core, AMD Ryzen 3, AMD Ryzen 3 Dual Core, AMD Ryzen 3 Hexa Core, AMD Ryzen 3 Quad Core, AMD Ryzen 5, AMD Ryzen 5 Dual Core, AMD Ryzen 5 Hexa Core, AMD Ryzen 5 Quad Core, AMD Ryzen 7 Octa Core, AMD Ryzen 7 Quad Core, AMD Ryzen 9 Octa Core, Intel Celeron Dual Core, Intel Celeron Quad Core, Intel Core i3, Intel Core i5, Intel Core i7, Intel Core i9, Intel Evo Core i5, Intel Pentium Quad Core, Intel Pentium Silver, M1, M1 Max, M1 Pro, M2, Qualcomm Snapdragon 7c Gen 2): M2\n",
            "Enter the Storage (1 TB HDD, 1 TB HDD, 128 GB SSD, 1 TB HDD, 256 GB SSD, 1 TB HDD, 512 GB SSD, 128 GB SSD, 256 GB SSD, 512 GB SSD): 1 TB HDD, 512 GB SSD\n",
            "Enter the Operating System (Chrome, DOS, Mac OS, Windows): Mac OS\n",
            "Enter the Brand (ALIENWARE, APPLE, ASUS, DELL, GIGABYTE, HP, Infinix, Lenovo, MSI, Nokia, RedmiBook, SAMSUNG, Ultimus, Vaio, acer, realme): APPLE\n",
            "Enter the RAM Size: 64.0\n",
            "Enter the Display Size: 16.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the query point\n",
        "query_point = {\n",
        "    'RAM_Type': dicts['RAM_Type'][ram_type],\n",
        "    'Processor': dicts['Processor'][processor],\n",
        "    'Storage': dicts['Storage'][storage],\n",
        "    'OS': dicts['OS'][os],\n",
        "    'Brand': dicts['Brand'][brand],\n",
        "    'RAM_Size': ram_size,\n",
        "    'Display': display\n",
        "}\n",
        "\n",
        "# Print the query point\n",
        "print(\"Query Point:\")\n",
        "print(query_point)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qX5hoPdFjVtU",
        "outputId": "0f8d1ae8-0bba-4340-94b2-9c138b242ee6"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query Point:\n",
            "{'RAM_Type': 6, 'Processor': 24, 'Storage': 3, 'OS': 2, 'Brand': 1, 'RAM_Size': 64.0, 'Display': 16.0}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define function to preprocess input data\n",
        "def preprocess_input_data(query_point, dicts_cols, scaler):\n",
        "   # Scale RAM_Size and Display using the scaler\n",
        "    query_point['RAM_Size'] = scaler.transform([[query_point['RAM_Size'], 0]])[0][0]\n",
        "    query_point['Display'] = scaler.transform([[query_point['Display'], 0]])[0][0]\n",
        "    return query_point\n",
        "\n",
        "# Apply preprocessing to the query point\n",
        "query_point_preprocessed = preprocess_input_data(query_point, dicts, scaler)\n",
        "\n",
        "# Convert the query point to a NumPy array\n",
        "query_array = np.array(list(query_point_preprocessed.values())).reshape(1, -1)\n",
        "\n",
        "# Print the query array\n",
        "print(\"Query Array:\")\n",
        "print(query_array)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mbjIGjTF3oMo",
        "outputId": "ef0e94bd-72bc-414a-babb-e0fbd56c597b"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query Array:\n",
            "[[ 6.         24.          3.          2.          1.          9.19298246\n",
            "   0.77192982]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query_point_transformed = scaler.transform(query_array[:, -2:])\n",
        "other_features = query_array[:, :-2]  # Select all columns except the last two\n",
        "query_point_transformed = np.concatenate((other_features, query_point_transformed), axis=1)\n",
        "\n",
        "query_point_transformed"
      ],
      "metadata": {
        "id": "QpaTTQ0B0C_p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b58c393a-04dc-4589-b7a7-7de3cca25d08"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 6.        , 24.        ,  3.        ,  2.        ,  1.        ,\n",
              "        -0.42228378, -0.11528822]])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "XGBoost Regressor"
      ],
      "metadata": {
        "id": "LZI7doEFxp3w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the predicted value\n",
        "y_pred = xgb_reg.predict(query_point_transformed)  \n",
        "\n",
        "# Back-transform the predicted value \n",
        "y_pred_orig = np.exp(y_pred)\n",
        "y_pred_orig"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rwajYb2rxjt4",
        "outputId": "a0e50ea4-1aec-4211-caf8-ccf07ec161d8"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([218494.17], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Gradient Boosting Regressor"
      ],
      "metadata": {
        "id": "fTAQ1_fqzMXJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the predicted value\n",
        "y_pred = gb_reg.predict(query_point_transformed)  \n",
        "\n",
        "# Back-transform the predicted value \n",
        "y_pred_orig = np.exp(y_pred)\n",
        "y_pred_orig"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f2BvMWJAzEXe",
        "outputId": "3e674118-11f7-43d3-b947-3efe661ba923"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([211977.33284989])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Random Forest Regressor"
      ],
      "metadata": {
        "id": "EEnSLo5pzWIy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the predicted value\n",
        "y_pred = rf_reg.predict(query_point_transformed)  \n",
        "\n",
        "# Back-transform the predicted value \n",
        "y_pred_orig = np.exp(y_pred)\n",
        "y_pred_orig"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ZTlaXDIzUnO",
        "outputId": "7c202c89-ff69-456c-e870-53f1883049b1"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([255248.56328981])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Random Forest model is way off. The best model is XGBoost. "
      ],
      "metadata": {
        "id": "GN5kD1gXzkbD"
      }
    }
  ]
}